{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "#from tensorflow.keras.utils import np_utils\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "aqEmXeElUsNA",
        "outputId": "1b02d988-2a63-436c-9c4a-0d26967c4bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "7WossKQaZc1v"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "data_to_load = files.upload()\n",
        "import io\n",
        "dataset = pd.read_csv(io.BytesIO(data_to_load['amharic.csv']))"
      ],
      "metadata": {
        "id": "nOWjMm3-UwiQ",
        "outputId": "4ee8ff38-d6d3-4349-d25d-8e56e407d36e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c4841e56-93ef-4357-af19-425b4bd8d3fb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c4841e56-93ef-4357-af19-425b4bd8d3fb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving amharic.csv to amharic.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "_caXLBGzVWxg",
        "outputId": "5156e269-e47a-473b-8592-4c8466302794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    labels                                              tweet Unnamed: 2\n",
              "0    Free   አስቀድሜ ጥያቄዬ በጨዋነት በውስጥ መስመር እንዲደርስዎ አድርጌ ፍትህን ለ...        NaN\n",
              "1   Free\\n   እነዚህን ወሳኝ ጉዳዮችን የሚያስፈፅም አካል እንዲቋቋምና ክትትል እንዲደ...        NaN\n",
              "2  Free \\n  የአማራ ህዝብ በአእምሮ ክንፉ ያልበረረበት ጥበብና ፍልስፍና ያልከፈተው የ...        NaN\n",
              "3   Free\\n  ከአማራ ህዝብ የሀገሪቱ ዘርፈ ብዙ እውቀት መንጭቶ የሞላበትከሙላቱም በመል...        NaN\n",
              "4   Hate\\n  ዛሬ በየትኛውም መለኪያ ይሁን መመዘኛ ኢትዮጵያዊነት የሚንፀባረቀው በአማራ...        NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8841d95c-5375-4121-9e3d-b177231e1fae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>tweet</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Free</td>\n",
              "      <td>አስቀድሜ ጥያቄዬ በጨዋነት በውስጥ መስመር እንዲደርስዎ አድርጌ ፍትህን ለ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Free\\n</td>\n",
              "      <td>እነዚህን ወሳኝ ጉዳዮችን የሚያስፈፅም አካል እንዲቋቋምና ክትትል እንዲደ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free \\n</td>\n",
              "      <td>የአማራ ህዝብ በአእምሮ ክንፉ ያልበረረበት ጥበብና ፍልስፍና ያልከፈተው የ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Free\\n</td>\n",
              "      <td>ከአማራ ህዝብ የሀገሪቱ ዘርፈ ብዙ እውቀት መንጭቶ የሞላበትከሙላቱም በመል...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hate\\n</td>\n",
              "      <td>ዛሬ በየትኛውም መለኪያ ይሁን መመዘኛ ኢትዮጵያዊነት የሚንፀባረቀው በአማራ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8841d95c-5375-4121-9e3d-b177231e1fae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8841d95c-5375-4121-9e3d-b177231e1fae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8841d95c-5375-4121-9e3d-b177231e1fae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet=dataset.tweet\n",
        "labels=dataset.labels"
      ],
      "metadata": {
        "id": "J-CYl1EtVdZ6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dataset['labels']=[re.sub(r\"\\n\", \"\", str(label)) for label in labels]\n",
        "\n",
        "     \n"
      ],
      "metadata": {
        "id": "tz5N43LGVg91"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# drop function which is used in removing or deleting rows or columns from the CSV files\n",
        "dataset.drop('Unnamed: 2', inplace=True, axis=1)\n",
        "\n",
        "# display\n",
        "print(\"\\nCSV Data after deleting the column 'Unnamed: 2':\\n\")\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "id": "HT9qZ8BAV6QH",
        "outputId": "4ba44f12-cd8a-4586-81de-7473ddd8ec54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CSV Data after deleting the column 'Unnamed: 2':\n",
            "\n",
            "      labels                                              tweet\n",
            "0      Free   አስቀድሜ ጥያቄዬ በጨዋነት በውስጥ መስመር እንዲደርስዎ አድርጌ ፍትህን ለ...\n",
            "1       Free   እነዚህን ወሳኝ ጉዳዮችን የሚያስፈፅም አካል እንዲቋቋምና ክትትል እንዲደ...\n",
            "2      Free   የአማራ ህዝብ በአእምሮ ክንፉ ያልበረረበት ጥበብና ፍልስፍና ያልከፈተው የ...\n",
            "3       Free  ከአማራ ህዝብ የሀገሪቱ ዘርፈ ብዙ እውቀት መንጭቶ የሞላበትከሙላቱም በመል...\n",
            "4       Hate  ዛሬ በየትኛውም መለኪያ ይሁን መመዘኛ ኢትዮጵያዊነት የሚንፀባረቀው በአማራ...\n",
            "...      ...                                                ...\n",
            "29995   Hate         በአሉ የሁሉም ኢትዮጵያዊ ስላልሆነ በኦሮምኛው ቢለፋደድ ምን አገባን\n",
            "29996   Free             ተባረክ አብቹ ፈር ቀዳጅ ስለሆንህ መጋረጃው መቀደድ ስለጀመረ\n",
            "29997   Free   እስከ አሁን አንተ ብቻ ነው በ   መፅሀፍ ያልቻልከው  አንተም ታሪክ እ...\n",
            "29998   Hate   ህገወጥት ጠቅላይ ሚንስትር ፅቤት የተፈቀደ ሆኖ ህዝብን እንዴት ህግ አክ...\n",
            "29999   Hate  ደነዙ ጠቅላይ ሚንስትር ፅቤት ህገመንግስት ሳይሻሻል በህግ የተወሰነዉን የ...\n",
            "\n",
            "[30000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = dataset['tweet']\n",
        "finalWords = []\n",
        "for word in words:\n",
        "    \n",
        "    \n",
        "    #remove any non-alphanumeric character\n",
        "    word = re.sub(r'\\W', ' ', str(word))\n",
        "    \n",
        "    #remove any digit\n",
        "    word = re.sub(\"(\\\\d)+\",\" \",word)\n",
        "    \n",
        "    #remove punctuation \n",
        "    word = re.sub(\",#'!:;\",\" \",word)\n",
        "    \n",
        "    #remove any latin characters \n",
        "    word = re.sub(r'[a-zA-Z]+', '', word)\n",
        "\n",
        "    word = re.sub('\\s+', ' ', word)  # remove extra whitespace\n",
        "    finalWords.append(word)\n"
      ],
      "metadata": {
        "id": "Gggkp0_KWUSA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizedList = []\n",
        "for lineWord in finalWords:\n",
        "    separatedWords = lineWord.split(' ')\n",
        "    word = [word for word in separatedWords if   word.strip() != '']\n",
        "    tokenizedList.append(word)"
      ],
      "metadata": {
        "id": "_OMeTmWIWf8H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list amharic stop words\n",
        "stopwords=['ነው', 'እና', 'እኔ', 'የእኔ','እኔ','ራሴ','እኛ','የእኛ','እኛ','ራሳችን','አንቺ' ,'የእርስዎ' ,'እራስዎ','እራሳችሁን','የእሱ',\n",
        "           'እሱ','እ','ራሱ','እሷ' 'ራሷን','እሱ','በራሱ','እነሱ','የእነሱ','እራሳቸው','ምንድን','የት','ማን','ይሄ','ያንን','እነዚህ','እነዚያ'\n",
        "           ,'ነው','እነዚህ','ናቸው','ነበር','ነበሩ','መሆን','ሆኗል','መሆን','አለ','ነበሩ','አለው','መስራት','ያደርገዋል','አደረጉት',\n",
        "           'ማድረግ','እና','ግን','ከሆነ','ወይም','ምክንያቱም','እንደ','እስከ','ገና','የ','ለ','ከ','ጋር','ስለ','መካከል','ውስጥ',\n",
        "           'ከዚህ','በፊት','በኋላ','ከላይ','ከታች','ወደ','ከ','ወደ','ላይ','ታች','ውስጥ','ውጭ','በላይ','በታች','በድጋሚ','እናስ','እናም']\n",
        "\n",
        "           \n",
        "cleanedWordsList= []\n",
        "for lineWords in tokenizedList:\n",
        "    tempList = []\n",
        "    for word in lineWords:\n",
        "        if word.strip() not in stopwords:\n",
        "            tempList.append(word)\n",
        "    cleanedWordsList.append(tempList)"
      ],
      "metadata": {
        "id": "xMDPfkbRWg5H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the time being this is fine but convert it to something good but not this at all\n",
        "\n",
        "normalizedSenteces = []\n",
        "for linesWords in cleanedWordsList:\n",
        "    tempList = []\n",
        "    for word in linesWords:\n",
        "        \n",
        "        word = re.sub(\"ሐ\",\"ሀ\",word)\n",
        "        word = re.sub(\"ሑ\",\"ሁ\",word)\n",
        "        word = re.sub(\"ሒ\",\"ሂ\",word)\n",
        "        word = re.sub(\"ሓ\",\"ሃ\",word)\n",
        "        word = re.sub(\"ሔ\",\"ሄ\",word)\n",
        "        word = re.sub(\"ሕ\",\"ህ\",word)\n",
        "        word = re.sub(\"ሖ\",\"ሆ\",word)\n",
        "        \n",
        "        word = re.sub(\"ኀ\",\"ሀ\",word)\n",
        "        word = re.sub(\"ኁ\",\"ሁ\",word)\n",
        "        word = re.sub(\"ኂ\",\"ሂ\",word)\n",
        "        word = re.sub(\"ኃ\",\"ሃ\",word)\n",
        "        word = re.sub(\"ኄ\",\"ሄ\",word)\n",
        "        word = re.sub(\"ኅ\",\"ህ\",word)\n",
        "        word = re.sub(\"ኆ\",\"ሆ\",word)\n",
        "        \n",
        "        word = re.sub(\"ሠ\",\"ሰ\",word)\n",
        "        word = re.sub(\"ሡ\",\"ሱ\",word)\n",
        "        word = re.sub(\"ሢ\",\"ሲ\",word)\n",
        "        word = re.sub(\"ሣ\",\"ሳ\",word)\n",
        "        word = re.sub(\"ሤ\",\"ሴ\",word)\n",
        "        word = re.sub(\"ሥ\",\"ስ\",word)\n",
        "        word = re.sub(\"ሦ\",\"ሶ\",word)\n",
        "        \n",
        "        word = re.sub(\"ዐ\",\"አ\",word)\n",
        "        word = re.sub(\"ዑ\",\"ኡ\",word)\n",
        "        word = re.sub(\"ዒ\",\"ኢ\",word)\n",
        "        word = re.sub(\"ዓ\",\"ኣ\",word)\n",
        "        word = re.sub(\"ዔ\",\"ኤ\",word)\n",
        "        word = re.sub(\"ዕ\",\"እ\",word)\n",
        "        word = re.sub(\"ዖ\",\"ኦ\",word)\n",
        "        \n",
        "        word = re.sub(\"ዐ\",\"አ\",word)\n",
        "        word = re.sub(\"ዑ\",\"ኡ\",word)\n",
        "        word = re.sub(\"ዒ\",\"ኢ\",word)\n",
        "        word = re.sub(\"ዓ\",\"ኣ\",word)\n",
        "        word = re.sub(\"ዔ\",\"ኤ\",word)\n",
        "        word = re.sub(\"ዕ\",\"እ\",word)\n",
        "        word = re.sub(\"ዖ\",\"ኦ\",word)\n",
        "        \n",
        "        word = re.sub(\"ጸ\",\"ፀ\",word)\n",
        "        word = re.sub(\"ጹ\",\"ፁ\",word)\n",
        "        word = re.sub(\"ጺ\",\"ፂ\",word)\n",
        "        word = re.sub(\"ጻ\",\"ፃ\",word)\n",
        "        word = re.sub(\"ጼ\",\"ፄ\",word)\n",
        "        word = re.sub(\"ጽ\",\"ፅ\",word)\n",
        "        word = re.sub(\"ጾ\",\"ፆ\",word)\n",
        "        \n",
        "        tempList.append(word)\n",
        "    normalizedSenteces.append(tempList)"
      ],
      "metadata": {
        "id": "ekDYWC1qWlP5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Split into training and testing data\n",
        "x = dataset['tweet']\n",
        "y = dataset['labels']"
      ],
      "metadata": {
        "id": "RwQgYCICW3M2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "H7OWx4ypXczf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-bzNTbsYfuow"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NGtMbbW7fylp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "x = np.array(dataset[\"tweet\"])\n",
        "y = np.array(dataset[\"labels\"])\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(x.astype('U')) \n",
        "#x = cv.fit_transform(x.apply(lambda x: np.str_(x)))\n",
        "#X = cv.fit_transform(x)# Fit the Data\n",
        "#Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Split the training set into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "     \n"
      ],
      "metadata": {
        "id": "NOjQH4r6Yf8h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"Training set size:\", X_train)\n",
        "     \n"
      ],
      "metadata": {
        "id": "UQz_d-rnYnFh",
        "outputId": "4f63fa98-5f92-431a-aa8d-4fa0776284fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size:   (0, 39510)\t1\n",
            "  (0, 105214)\t1\n",
            "  (1, 10680)\t1\n",
            "  (1, 1298)\t1\n",
            "  (1, 80957)\t1\n",
            "  (1, 54732)\t1\n",
            "  (1, 15876)\t1\n",
            "  (1, 100601)\t1\n",
            "  (1, 750)\t1\n",
            "  (1, 96505)\t1\n",
            "  (1, 8652)\t1\n",
            "  (1, 80024)\t1\n",
            "  (1, 80415)\t1\n",
            "  (1, 33332)\t1\n",
            "  (1, 96792)\t1\n",
            "  (1, 102380)\t1\n",
            "  (1, 98024)\t1\n",
            "  (1, 28242)\t1\n",
            "  (1, 105560)\t1\n",
            "  (1, 14727)\t1\n",
            "  (1, 54294)\t1\n",
            "  (1, 94490)\t1\n",
            "  (1, 43241)\t1\n",
            "  (1, 48168)\t1\n",
            "  (1, 78942)\t1\n",
            "  :\t:\n",
            "  (17998, 6760)\t1\n",
            "  (17998, 35720)\t1\n",
            "  (17998, 56540)\t1\n",
            "  (17998, 62401)\t1\n",
            "  (17998, 110149)\t1\n",
            "  (17998, 24521)\t1\n",
            "  (17998, 475)\t1\n",
            "  (17998, 12427)\t1\n",
            "  (17998, 108074)\t1\n",
            "  (17998, 13733)\t1\n",
            "  (17998, 49485)\t1\n",
            "  (17998, 35970)\t1\n",
            "  (17998, 14177)\t1\n",
            "  (17998, 23584)\t1\n",
            "  (17998, 11818)\t1\n",
            "  (17998, 30839)\t1\n",
            "  (17998, 9819)\t1\n",
            "  (17998, 18088)\t1\n",
            "  (17998, 14611)\t1\n",
            "  (17998, 66349)\t1\n",
            "  (17999, 8652)\t1\n",
            "  (17999, 80777)\t1\n",
            "  (17999, 63336)\t1\n",
            "  (17999, 54455)\t1\n",
            "  (17999, 92993)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing set size:\",X_test)"
      ],
      "metadata": {
        "id": "lXIfVL-QYs4I",
        "outputId": "cfb22ea1-19c3-4a2e-f7e8-7bb5f5bb2a83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing set size:   (0, 44755)\t2\n",
            "  (0, 6760)\t1\n",
            "  (0, 105895)\t1\n",
            "  (0, 15901)\t1\n",
            "  (0, 100569)\t1\n",
            "  (0, 111682)\t1\n",
            "  (0, 111623)\t1\n",
            "  (0, 99878)\t1\n",
            "  (0, 45440)\t1\n",
            "  (0, 17976)\t1\n",
            "  (0, 86487)\t1\n",
            "  (0, 35163)\t1\n",
            "  (0, 16818)\t1\n",
            "  (0, 56137)\t1\n",
            "  (0, 13795)\t1\n",
            "  (0, 31674)\t1\n",
            "  (0, 92475)\t1\n",
            "  (0, 55212)\t1\n",
            "  (0, 66744)\t1\n",
            "  (0, 108137)\t1\n",
            "  (0, 39399)\t1\n",
            "  (1, 44755)\t1\n",
            "  (1, 71642)\t1\n",
            "  (1, 49047)\t1\n",
            "  (1, 92082)\t1\n",
            "  :\t:\n",
            "  (5999, 49630)\t1\n",
            "  (5999, 109409)\t1\n",
            "  (5999, 111326)\t1\n",
            "  (5999, 27168)\t1\n",
            "  (5999, 104628)\t1\n",
            "  (5999, 13085)\t1\n",
            "  (5999, 81326)\t1\n",
            "  (5999, 111994)\t1\n",
            "  (5999, 25558)\t1\n",
            "  (5999, 39639)\t1\n",
            "  (5999, 41764)\t2\n",
            "  (5999, 15844)\t1\n",
            "  (5999, 59239)\t1\n",
            "  (5999, 8463)\t1\n",
            "  (5999, 6840)\t1\n",
            "  (5999, 13687)\t1\n",
            "  (5999, 8056)\t1\n",
            "  (5999, 7128)\t1\n",
            "  (5999, 69313)\t1\n",
            "  (5999, 112109)\t1\n",
            "  (5999, 70854)\t1\n",
            "  (5999, 82733)\t1\n",
            "  (5999, 10708)\t1\n",
            "  (5999, 66765)\t1\n",
            "  (5999, 23921)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"Training set size:\", X_val)\n",
        "     \n"
      ],
      "metadata": {
        "id": "GkHuH9WzY0WH",
        "outputId": "dea4e821-0182-4ca1-9263-3e3002952e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size:   (0, 44755)\t1\n",
            "  (0, 63043)\t1\n",
            "  (0, 110317)\t1\n",
            "  (0, 63259)\t1\n",
            "  (0, 38022)\t1\n",
            "  (0, 29451)\t1\n",
            "  (0, 17841)\t1\n",
            "  (0, 62820)\t1\n",
            "  (0, 35714)\t1\n",
            "  (0, 52096)\t1\n",
            "  (0, 37666)\t1\n",
            "  (0, 46519)\t1\n",
            "  (0, 34527)\t1\n",
            "  (0, 109699)\t1\n",
            "  (0, 94976)\t1\n",
            "  (0, 76353)\t1\n",
            "  (0, 68940)\t1\n",
            "  (0, 6256)\t1\n",
            "  (0, 15444)\t1\n",
            "  (0, 68970)\t1\n",
            "  (0, 87604)\t1\n",
            "  (1, 78432)\t1\n",
            "  (1, 48255)\t1\n",
            "  (1, 36008)\t1\n",
            "  (1, 61343)\t1\n",
            "  :\t:\n",
            "  (5998, 40650)\t1\n",
            "  (5998, 57019)\t1\n",
            "  (5998, 64129)\t1\n",
            "  (5998, 57577)\t1\n",
            "  (5998, 77397)\t1\n",
            "  (5998, 3360)\t3\n",
            "  (5998, 25042)\t1\n",
            "  (5998, 77700)\t1\n",
            "  (5998, 80002)\t1\n",
            "  (5998, 11763)\t1\n",
            "  (5999, 82917)\t1\n",
            "  (5999, 44755)\t3\n",
            "  (5999, 107587)\t1\n",
            "  (5999, 9451)\t1\n",
            "  (5999, 81631)\t1\n",
            "  (5999, 22185)\t1\n",
            "  (5999, 58317)\t3\n",
            "  (5999, 39096)\t1\n",
            "  (5999, 83686)\t1\n",
            "  (5999, 8273)\t1\n",
            "  (5999, 82397)\t1\n",
            "  (5999, 32708)\t1\n",
            "  (5999, 52519)\t2\n",
            "  (5999, 2829)\t1\n",
            "  (5999, 90500)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train\n",
        "     \n"
      ],
      "metadata": {
        "id": "66roFuElY4uv",
        "outputId": "7f8a0bbd-623a-4d1f-bc6d-ed2ac16bd99b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<18000x112739 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 306573 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_train\n",
        "     \n"
      ],
      "metadata": {
        "id": "msH6J6JQY7sY",
        "outputId": "665c698d-cd62-4a62-ef53-e7cdc76b961e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Hate', 'Free', 'Free', ..., 'Hate', 'Hate', 'Hate'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_test\n",
        "     \n"
      ],
      "metadata": {
        "id": "9T0WrbykY_xh",
        "outputId": "4ef1892a-49df-40cc-d571-d4586ac552d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6000x112739 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 100858 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "y_test\n",
        "     \n"
      ],
      "metadata": {
        "id": "3Y9Q9zbIZBTv",
        "outputId": "1d88c42b-429c-4ee2-8c0a-246d2b5cadee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Free', 'Free', 'Free', ..., 'Hate', 'Hate', 'Hate'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "#model.score(X_test,y_test)\n",
        "# Define hyperparameters\n",
        "max_depths = [67,2,5,9,4,6,100,1000] # maximum depth of the tree ,0\n",
        "min_samples_splits = [1001,89,90,34,45,65,254] # minimum number of samples required to split an internal node 2\n",
        "min_samples_leaves = [890,2001,2400,67,544,560,679,2] # minimum number of samples required to be at a leaf node \n",
        "# Train the model with different hyperparameters\n",
        "for max_depth in max_depths:\n",
        "    for min_samples_split in min_samples_splits:\n",
        "        for min_samples_leaf in min_samples_leaves:\n",
        "            # Define the model\n",
        "            model = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,criterion='gini')\n",
        "            # Train the model\n",
        "            model.fit(X_train, y_train)\n",
        "           #train and test\n",
        "            score = model.score(X_test, y_test)\n",
        "           \n",
        "            # Print the results\n",
        "            print(f\"Max depth: {max_depth}, Min samples split: {min_samples_split}, Min samples leaf: {min_samples_leaf}, Accuracy score: {score}\")\n",
        "\n",
        "     \n"
      ],
      "metadata": {
        "id": "npEetjpqZGoS",
        "outputId": "d60abe57-13b7-4463-e54d-26932dba7c08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max depth: 67, Min samples split: 1001, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 1001, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 1001, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 1001, Min samples leaf: 67, Accuracy score: 0.5733333333333334\n",
            "Max depth: 67, Min samples split: 1001, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 1001, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 1001, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 1001, Min samples leaf: 2, Accuracy score: 0.5813333333333334\n",
            "Max depth: 67, Min samples split: 89, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 89, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 89, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 89, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 67, Min samples split: 89, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 89, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 89, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 89, Min samples leaf: 2, Accuracy score: 0.5728333333333333\n",
            "Max depth: 67, Min samples split: 90, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 90, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 90, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 90, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 67, Min samples split: 90, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 90, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 90, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 90, Min samples leaf: 2, Accuracy score: 0.577\n",
            "Max depth: 67, Min samples split: 34, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 34, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 34, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 34, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 67, Min samples split: 34, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 34, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 34, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 34, Min samples leaf: 2, Accuracy score: 0.5751666666666667\n",
            "Max depth: 67, Min samples split: 45, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 45, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 45, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 45, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 67, Min samples split: 45, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 45, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 45, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 45, Min samples leaf: 2, Accuracy score: 0.5733333333333334\n",
            "Max depth: 67, Min samples split: 65, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 65, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 65, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 65, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 67, Min samples split: 65, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 65, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 65, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 65, Min samples leaf: 2, Accuracy score: 0.5751666666666667\n",
            "Max depth: 67, Min samples split: 254, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 254, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 254, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 67, Min samples split: 254, Min samples leaf: 67, Accuracy score: 0.5733333333333334\n",
            "Max depth: 67, Min samples split: 254, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 254, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 67, Min samples split: 254, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 67, Min samples split: 254, Min samples leaf: 2, Accuracy score: 0.576\n",
            "Max depth: 2, Min samples split: 1001, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 1001, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 1001, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 1001, Min samples leaf: 67, Accuracy score: 0.5115\n",
            "Max depth: 2, Min samples split: 1001, Min samples leaf: 544, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 1001, Min samples leaf: 560, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 1001, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 1001, Min samples leaf: 2, Accuracy score: 0.5115\n",
            "Max depth: 2, Min samples split: 89, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 89, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 89, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 89, Min samples leaf: 67, Accuracy score: 0.5115\n",
            "Max depth: 2, Min samples split: 89, Min samples leaf: 544, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 89, Min samples leaf: 560, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 89, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 89, Min samples leaf: 2, Accuracy score: 0.5113333333333333\n",
            "Max depth: 2, Min samples split: 90, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 90, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 90, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 90, Min samples leaf: 67, Accuracy score: 0.5115\n",
            "Max depth: 2, Min samples split: 90, Min samples leaf: 544, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 90, Min samples leaf: 560, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 90, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 90, Min samples leaf: 2, Accuracy score: 0.5113333333333333\n",
            "Max depth: 2, Min samples split: 34, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 34, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 34, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 34, Min samples leaf: 67, Accuracy score: 0.5115\n",
            "Max depth: 2, Min samples split: 34, Min samples leaf: 544, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 34, Min samples leaf: 560, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 34, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 34, Min samples leaf: 2, Accuracy score: 0.5113333333333333\n",
            "Max depth: 2, Min samples split: 45, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 45, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 45, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 45, Min samples leaf: 67, Accuracy score: 0.5115\n",
            "Max depth: 2, Min samples split: 45, Min samples leaf: 544, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 45, Min samples leaf: 560, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 45, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 45, Min samples leaf: 2, Accuracy score: 0.5113333333333333\n",
            "Max depth: 2, Min samples split: 65, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 65, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 65, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 65, Min samples leaf: 67, Accuracy score: 0.5115\n",
            "Max depth: 2, Min samples split: 65, Min samples leaf: 544, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 65, Min samples leaf: 560, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 65, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 65, Min samples leaf: 2, Accuracy score: 0.5113333333333333\n",
            "Max depth: 2, Min samples split: 254, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 254, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 254, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 2, Min samples split: 254, Min samples leaf: 67, Accuracy score: 0.5115\n",
            "Max depth: 2, Min samples split: 254, Min samples leaf: 544, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 254, Min samples leaf: 560, Accuracy score: 0.511\n",
            "Max depth: 2, Min samples split: 254, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 2, Min samples split: 254, Min samples leaf: 2, Accuracy score: 0.5115\n",
            "Max depth: 5, Min samples split: 1001, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 1001, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 1001, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 1001, Min samples leaf: 67, Accuracy score: 0.5325\n",
            "Max depth: 5, Min samples split: 1001, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 1001, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 1001, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 1001, Min samples leaf: 2, Accuracy score: 0.5331666666666667\n",
            "Max depth: 5, Min samples split: 89, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 89, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 89, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 89, Min samples leaf: 67, Accuracy score: 0.5325\n",
            "Max depth: 5, Min samples split: 89, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 89, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 89, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 89, Min samples leaf: 2, Accuracy score: 0.5321666666666667\n",
            "Max depth: 5, Min samples split: 90, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 90, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 90, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 90, Min samples leaf: 67, Accuracy score: 0.5325\n",
            "Max depth: 5, Min samples split: 90, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 90, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 90, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 90, Min samples leaf: 2, Accuracy score: 0.5321666666666667\n",
            "Max depth: 5, Min samples split: 34, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 34, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 34, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 34, Min samples leaf: 67, Accuracy score: 0.5325\n",
            "Max depth: 5, Min samples split: 34, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 34, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 34, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 34, Min samples leaf: 2, Accuracy score: 0.5321666666666667\n",
            "Max depth: 5, Min samples split: 45, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 45, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 45, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 45, Min samples leaf: 67, Accuracy score: 0.5325\n",
            "Max depth: 5, Min samples split: 45, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 45, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 45, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 45, Min samples leaf: 2, Accuracy score: 0.5323333333333333\n",
            "Max depth: 5, Min samples split: 65, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 65, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 65, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 65, Min samples leaf: 67, Accuracy score: 0.5325\n",
            "Max depth: 5, Min samples split: 65, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 65, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 65, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 65, Min samples leaf: 2, Accuracy score: 0.5321666666666667\n",
            "Max depth: 5, Min samples split: 254, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 254, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 254, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 5, Min samples split: 254, Min samples leaf: 67, Accuracy score: 0.5325\n",
            "Max depth: 5, Min samples split: 254, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 254, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 5, Min samples split: 254, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 5, Min samples split: 254, Min samples leaf: 2, Accuracy score: 0.5323333333333333\n",
            "Max depth: 9, Min samples split: 1001, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 1001, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 1001, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 1001, Min samples leaf: 67, Accuracy score: 0.5401666666666667\n",
            "Max depth: 9, Min samples split: 1001, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 1001, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 1001, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 1001, Min samples leaf: 2, Accuracy score: 0.5405\n",
            "Max depth: 9, Min samples split: 89, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 89, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 89, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 89, Min samples leaf: 67, Accuracy score: 0.5401666666666667\n",
            "Max depth: 9, Min samples split: 89, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 89, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 89, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 89, Min samples leaf: 2, Accuracy score: 0.5376666666666666\n",
            "Max depth: 9, Min samples split: 90, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 90, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 90, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 90, Min samples leaf: 67, Accuracy score: 0.5401666666666667\n",
            "Max depth: 9, Min samples split: 90, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 90, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 90, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 90, Min samples leaf: 2, Accuracy score: 0.537\n",
            "Max depth: 9, Min samples split: 34, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 34, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 34, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 34, Min samples leaf: 67, Accuracy score: 0.5401666666666667\n",
            "Max depth: 9, Min samples split: 34, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 34, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 34, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 34, Min samples leaf: 2, Accuracy score: 0.5371666666666667\n",
            "Max depth: 9, Min samples split: 45, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 45, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 45, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 45, Min samples leaf: 67, Accuracy score: 0.5401666666666667\n",
            "Max depth: 9, Min samples split: 45, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 45, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 45, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 45, Min samples leaf: 2, Accuracy score: 0.5371666666666667\n",
            "Max depth: 9, Min samples split: 65, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 65, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 65, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 65, Min samples leaf: 67, Accuracy score: 0.5401666666666667\n",
            "Max depth: 9, Min samples split: 65, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 65, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 65, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 65, Min samples leaf: 2, Accuracy score: 0.5376666666666666\n",
            "Max depth: 9, Min samples split: 254, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 254, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 254, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 9, Min samples split: 254, Min samples leaf: 67, Accuracy score: 0.5401666666666667\n",
            "Max depth: 9, Min samples split: 254, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 254, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 9, Min samples split: 254, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 9, Min samples split: 254, Min samples leaf: 2, Accuracy score: 0.5373333333333333\n",
            "Max depth: 4, Min samples split: 1001, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 1001, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 1001, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 1001, Min samples leaf: 67, Accuracy score: 0.525\n",
            "Max depth: 4, Min samples split: 1001, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 1001, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 1001, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 1001, Min samples leaf: 2, Accuracy score: 0.5256666666666666\n",
            "Max depth: 4, Min samples split: 89, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 89, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 89, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 89, Min samples leaf: 67, Accuracy score: 0.525\n",
            "Max depth: 4, Min samples split: 89, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 89, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 89, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 89, Min samples leaf: 2, Accuracy score: 0.5255\n",
            "Max depth: 4, Min samples split: 90, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 90, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 90, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 90, Min samples leaf: 67, Accuracy score: 0.525\n",
            "Max depth: 4, Min samples split: 90, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 90, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 90, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 90, Min samples leaf: 2, Accuracy score: 0.5255\n",
            "Max depth: 4, Min samples split: 34, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 34, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 34, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 34, Min samples leaf: 67, Accuracy score: 0.525\n",
            "Max depth: 4, Min samples split: 34, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 34, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 34, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 34, Min samples leaf: 2, Accuracy score: 0.5255\n",
            "Max depth: 4, Min samples split: 45, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 45, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 45, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 45, Min samples leaf: 67, Accuracy score: 0.525\n",
            "Max depth: 4, Min samples split: 45, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 45, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 45, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 45, Min samples leaf: 2, Accuracy score: 0.5253333333333333\n",
            "Max depth: 4, Min samples split: 65, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 65, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 65, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 65, Min samples leaf: 67, Accuracy score: 0.525\n",
            "Max depth: 4, Min samples split: 65, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 65, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 65, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 65, Min samples leaf: 2, Accuracy score: 0.5255\n",
            "Max depth: 4, Min samples split: 254, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 254, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 254, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 4, Min samples split: 254, Min samples leaf: 67, Accuracy score: 0.525\n",
            "Max depth: 4, Min samples split: 254, Min samples leaf: 544, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 254, Min samples leaf: 560, Accuracy score: 0.5316666666666666\n",
            "Max depth: 4, Min samples split: 254, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 4, Min samples split: 254, Min samples leaf: 2, Accuracy score: 0.5256666666666666\n",
            "Max depth: 6, Min samples split: 1001, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 1001, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 1001, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 1001, Min samples leaf: 67, Accuracy score: 0.5361666666666667\n",
            "Max depth: 6, Min samples split: 1001, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 1001, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 1001, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 1001, Min samples leaf: 2, Accuracy score: 0.537\n",
            "Max depth: 6, Min samples split: 89, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 89, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 89, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 89, Min samples leaf: 67, Accuracy score: 0.5361666666666667\n",
            "Max depth: 6, Min samples split: 89, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 89, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 89, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 89, Min samples leaf: 2, Accuracy score: 0.5356666666666666\n",
            "Max depth: 6, Min samples split: 90, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 90, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 90, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 90, Min samples leaf: 67, Accuracy score: 0.5361666666666667\n",
            "Max depth: 6, Min samples split: 90, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 90, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 90, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 90, Min samples leaf: 2, Accuracy score: 0.5355\n",
            "Max depth: 6, Min samples split: 34, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 34, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 34, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 34, Min samples leaf: 67, Accuracy score: 0.5361666666666667\n",
            "Max depth: 6, Min samples split: 34, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 34, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 34, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 34, Min samples leaf: 2, Accuracy score: 0.5358333333333334\n",
            "Max depth: 6, Min samples split: 45, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 45, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 45, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 45, Min samples leaf: 67, Accuracy score: 0.5361666666666667\n",
            "Max depth: 6, Min samples split: 45, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 45, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 45, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 45, Min samples leaf: 2, Accuracy score: 0.536\n",
            "Max depth: 6, Min samples split: 65, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 65, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 65, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 65, Min samples leaf: 67, Accuracy score: 0.5361666666666667\n",
            "Max depth: 6, Min samples split: 65, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 65, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 65, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 65, Min samples leaf: 2, Accuracy score: 0.5355\n",
            "Max depth: 6, Min samples split: 254, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 254, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 254, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 6, Min samples split: 254, Min samples leaf: 67, Accuracy score: 0.5361666666666667\n",
            "Max depth: 6, Min samples split: 254, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 254, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 6, Min samples split: 254, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 6, Min samples split: 254, Min samples leaf: 2, Accuracy score: 0.536\n",
            "Max depth: 100, Min samples split: 1001, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 1001, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 1001, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 1001, Min samples leaf: 67, Accuracy score: 0.5733333333333334\n",
            "Max depth: 100, Min samples split: 1001, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 1001, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 1001, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 1001, Min samples leaf: 2, Accuracy score: 0.584\n",
            "Max depth: 100, Min samples split: 89, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 89, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 89, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 89, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 100, Min samples split: 89, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 89, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 89, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 89, Min samples leaf: 2, Accuracy score: 0.5781666666666667\n",
            "Max depth: 100, Min samples split: 90, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 90, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 90, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 90, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 100, Min samples split: 90, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 90, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 90, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 90, Min samples leaf: 2, Accuracy score: 0.5766666666666667\n",
            "Max depth: 100, Min samples split: 34, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 34, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 34, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 34, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 100, Min samples split: 34, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 34, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 34, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 34, Min samples leaf: 2, Accuracy score: 0.5776666666666667\n",
            "Max depth: 100, Min samples split: 45, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 45, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 45, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 45, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 100, Min samples split: 45, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 45, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 45, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 45, Min samples leaf: 2, Accuracy score: 0.573\n",
            "Max depth: 100, Min samples split: 65, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 65, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 65, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 65, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 100, Min samples split: 65, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 65, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 65, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 65, Min samples leaf: 2, Accuracy score: 0.577\n",
            "Max depth: 100, Min samples split: 254, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 254, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 254, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 100, Min samples split: 254, Min samples leaf: 67, Accuracy score: 0.5733333333333334\n",
            "Max depth: 100, Min samples split: 254, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 254, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 100, Min samples split: 254, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 100, Min samples split: 254, Min samples leaf: 2, Accuracy score: 0.5833333333333334\n",
            "Max depth: 1000, Min samples split: 1001, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 1001, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 1001, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 1001, Min samples leaf: 67, Accuracy score: 0.5733333333333334\n",
            "Max depth: 1000, Min samples split: 1001, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 1001, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 1001, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 1001, Min samples leaf: 2, Accuracy score: 0.6071666666666666\n",
            "Max depth: 1000, Min samples split: 89, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 89, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 89, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 89, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 1000, Min samples split: 89, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 89, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 89, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 89, Min samples leaf: 2, Accuracy score: 0.5966666666666667\n",
            "Max depth: 1000, Min samples split: 90, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 90, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 90, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 90, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 1000, Min samples split: 90, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 90, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 90, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 90, Min samples leaf: 2, Accuracy score: 0.5993333333333334\n",
            "Max depth: 1000, Min samples split: 34, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 34, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 34, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 34, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 1000, Min samples split: 34, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 34, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 34, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 34, Min samples leaf: 2, Accuracy score: 0.6035\n",
            "Max depth: 1000, Min samples split: 45, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 45, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 45, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 45, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 1000, Min samples split: 45, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 45, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 45, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 45, Min samples leaf: 2, Accuracy score: 0.6003333333333334\n",
            "Max depth: 1000, Min samples split: 65, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 65, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 65, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 65, Min samples leaf: 67, Accuracy score: 0.5755\n",
            "Max depth: 1000, Min samples split: 65, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 65, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 65, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 65, Min samples leaf: 2, Accuracy score: 0.6068333333333333\n",
            "Max depth: 1000, Min samples split: 254, Min samples leaf: 890, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 254, Min samples leaf: 2001, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 254, Min samples leaf: 2400, Accuracy score: 0.515\n",
            "Max depth: 1000, Min samples split: 254, Min samples leaf: 67, Accuracy score: 0.5733333333333334\n",
            "Max depth: 1000, Min samples split: 254, Min samples leaf: 544, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 254, Min samples leaf: 560, Accuracy score: 0.5333333333333333\n",
            "Max depth: 1000, Min samples split: 254, Min samples leaf: 679, Accuracy score: 0.5288333333333334\n",
            "Max depth: 1000, Min samples split: 254, Min samples leaf: 2, Accuracy score: 0.605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "            # Evaluate the model's performance\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "-CRzof8YeFn8",
        "outputId": "bd1a00fc-c19d-49d9-8362-bfd1fa14392e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Free       0.60      0.60      0.60      2986\n",
            "       Free        0.00      0.00      0.00         1\n",
            "        Hate       0.61      0.61      0.61      3013\n",
            "\n",
            "    accuracy                           0.60      6000\n",
            "   macro avg       0.40      0.40      0.40      6000\n",
            "weighted avg       0.60      0.60      0.60      6000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))"
      ],
      "metadata": {
        "id": "wLJZL081ew6Q",
        "outputId": "49f297cd-c020-45a6-a374-28dd18335277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6050469925837445"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting the outcome ***"
      ],
      "metadata": {
        "id": "GvYzsRsZ6nWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the outcome\n",
        "inp =input(\"Enter post :                 \")\n",
        "dp = cv.transform([inp]).toarray()\n",
        "dt=model.predict(dp)\n",
        "if dt=='Hate Speech':\n",
        "    print(\"//////////////////////////////\")\n",
        "    print(\"/////the post is blocked//////\")\n",
        "    print(\"//////////////////////////////\")\n",
        "elif dt=='Offensive Speech':\n",
        "    print(\"Warnnig.....\")\n",
        "    print(\"Warnnig.....\")\n",
        "    print(\"Warnnig.....\")\n",
        "    print(inp)\n",
        "\n",
        "else:\n",
        "    print(inp)\n",
        "   \n",
        "print(dt)"
      ],
      "metadata": {
        "id": "lQWtT2qExdah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "P8ChsoZeqJtp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}